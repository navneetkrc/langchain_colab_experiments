{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/navneetkrc/langchain_colab_experiments/blob/main/QA_app_using_Pinecone_openai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install"
      ],
      "metadata": {
        "id": "DUlgyRebGtNg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoZ7VisnE0iP"
      },
      "outputs": [],
      "source": [
        "!pip install openai pinecone-client python-docx"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "Da7fjJn2JDkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pinecone\n",
        "from openai.embeddings_utils import get_embedding\n",
        "from tqdm import tqdm\n",
        "import docx\n",
        "import os\n",
        "import openai\n",
        "\n",
        "openai.api_key = \"YOUR_API_KEY_HERE\""
      ],
      "metadata": {
        "id": "vzabQYDmIEYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount drive a specify the folder"
      ],
      "metadata": {
        "id": "Vc9vsSXNMsa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "S3bU_eUOJCT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs_path = \"/content/drive/MyDrive/Your Docs Folder\""
      ],
      "metadata": {
        "id": "rR7IbBDSMwaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parse Documents"
      ],
      "metadata": {
        "id": "B7C2eh4TVOPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks = []\n",
        "for f_name in os.listdir(docs_path):\n",
        "  doc_path = os.path.join(docs_path, f_name)\n",
        "  doc = docx.Document(doc_path)\n",
        "  for para in doc.paragraphs:\n",
        "    text_chunks.append(para.text)"
      ],
      "metadata": {
        "id": "PTDRN9P5T2B9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove all chunks shorter than 10 words and strip the rest\n",
        "text_chunks = [string.strip().strip('\\n') for string in text_chunks if len(string.split()) >= 10]"
      ],
      "metadata": {
        "id": "4aFLhBnbZ8-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate embeddigns"
      ],
      "metadata": {
        "id": "RB7bq2ucbGeD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunks_with_embeddigns = []\n",
        "for chunk in tqdm(text_chunks):\n",
        "  embedding = get_embedding(chunk, engine='text-embedding-ada-002')\n",
        "  chunks_with_embeddigns.append({\"text\": chunk, \"embedding\": embedding})"
      ],
      "metadata": {
        "id": "UOK6ovzbbFNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload to Pinecone"
      ],
      "metadata": {
        "id": "Kc_xdNnAduLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pinecone.init(\n",
        "    api_key=\"\",\n",
        "    environment=\"us-east1-gcp\"\n",
        ")"
      ],
      "metadata": {
        "id": "L1jcoDObeLO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create or connect to index\n",
        "index_name = \"tiktok-trends-2023\"\n",
        "\n",
        "if index_name not in pinecone.list_indexes():\n",
        "    pinecone.create_index(index_name, dimension=1536)\n",
        "# connect to index\n",
        "index = pinecone.Index(index_name)"
      ],
      "metadata": {
        "id": "uq6ABbtVdGOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64  # process everything in batches of 64\n",
        "for i in tqdm(range(0, len(chunks_with_embeddigns), batch_size)):\n",
        "    data_batch = chunks_with_embeddigns.iloc[i: i+batch_size]\n",
        "    # set end position of batch\n",
        "    i_end = min(i+batch_size, len(chunks_with_embeddigns))\n",
        "    # get batch meta\n",
        "    text_batch = [item['text'] for item in data_batch]\n",
        "    # get ids\n",
        "    ids_batch = [str(n) for n in range(i, i_end)]\n",
        "    # get embeddings\n",
        "    embeds = [item['embedding'] for item in data_batch]\n",
        "    # prep metadata and upsert batch\n",
        "    meta = [{'text': text_batch} for text_batch in zip(text_batch)] # you can add more fields here\n",
        "    to_upsert = zip(ids_batch, embeds, meta)\n",
        "    # upsert to Pinecone\n",
        "    index.upsert(vectors=list(to_upsert))"
      ],
      "metadata": {
        "id": "0dSrfmyUe0p6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Query Index"
      ],
      "metadata": {
        "id": "sWVFk3fyGzwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search_docs(query):\n",
        "  xq = openai.Embedding.create(input=query, engine=\"text-embedding-ada-002\")['data'][0]['embedding']\n",
        "  res = index.query([xq], top_k=5, include_metadata=True)\n",
        "  chosen_text = []\n",
        "  for match in res['matches']:\n",
        "    chosen_text = match['metadata']\n",
        "  return res['matches']"
      ],
      "metadata": {
        "id": "MawACaJnG0we"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matches = search_docs(\"What are some predictions for tiktok?\")\n",
        "for match in matches:\n",
        "    print(f\"{match['score']:.2f}: {match['metadata']}\")"
      ],
      "metadata": {
        "id": "0Vnoi_NaHSu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Construct Prompt"
      ],
      "metadata": {
        "id": "H9C11iMnH8ux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def construct_prompt(query):\n",
        "  matches = search_docs(query)\n",
        "\n",
        "  chosen_text = []\n",
        "  for match in matches:\n",
        "    chosen_text.append(match['metadata']['text'])\n",
        "\n",
        "  prompt = \"\"\"Answer the question as truthfully as possible using the context below, and if the answer is no within the context, say 'I don't know.'\"\"\"\n",
        "  prompt += \"\\n\\n\"\n",
        "  prompt += \"Context: \" + \"\\n\".join(chosen_text)\n",
        "  prompt += \"\\n\\n\"\n",
        "  prompt += \"Question: \" + query\n",
        "  prompt += \"\\n\"\n",
        "  prompt += \"Answer: \"\n",
        "  return prompt"
      ],
      "metadata": {
        "id": "IhxkkHunIA38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the model"
      ],
      "metadata": {
        "id": "pXMXg_JHIh05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_question(query):\n",
        "  prompt = construct_prompt(query)\n",
        "  res = openai.Completion.create(\n",
        "      prompt=prompt,\n",
        "      model=\"text-davinci-003\",\n",
        "      max_tokens=500,\n",
        "      temperature=0.0,\n",
        "  )\n",
        "  \n",
        "  return res.choices[0].message"
      ],
      "metadata": {
        "id": "OAVPi_p_MyuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(answer_question(\"What will be the top platform in 2023?\"))"
      ],
      "metadata": {
        "id": "nlrzWiqQIkGs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}